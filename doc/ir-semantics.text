# The formal language

P ::= Function main  ↦ F, (Df ↦ F)*      program:            main function and other functions
F ::= Segment active ↦ G, (Dg ↦ G)*      function body:      can contain multiple versions -- active segment and others
G ::= start ↦ i, I                       a function version: instruction stream with dedicated start
I ::= (l ↦ i)*                           instruction stream: labeled instructions

Df ::= Function f(x, ...)          function declaration
Dg ::= Segment  g                  segment declaration

x        variables

f  function name
g  segment name
l  labels

Reserved Names:
main      main function    (execution of program starts here)
active    active segment   (function call executes this segment)
start     start label      (execution of segment starts here)

a  addresses

i ::=    instructions
| const x = ce                  constant variable
| mut x = e                     mutable variable
| x <- e                        assignment
| branch e l₁ l₂                conditional
| goto l                        goto
| print e                       print
| return e                      return
| osr(e, g, l, osr-map*)        osr : (can be used for osr-in and osr-out)

ce ::=   call expression
| e
| call f (e, ...)     call

e ::=    (simple) expressions
| lit                   literals
| x                     variables
| primop(x, ...)        primitive operation (pure)

lit ::=  litterals
| nil
| true | false
| 0 | 1 | 2 | ...

v :=     values
| lit                   literals

(Note: heap adresses are not values)

osr-map ::=    osr mapping declaration
| const x = e
| mut x
| mut x = x

# Natural operational semantics

E ::= (x ↦ const v | x ↦ var a | x ↦ ⊥)*  lexical environment
H ::= (l ↦ v)                             mutable heap

T ::= (lit)*                    output trace

## Configuration

  C ::= (x, E, I, l)                 continuation:  accumulator, environment, instructions, label

  M ::= (P, C*) : (I, T, H, E, l)    machine state: program, continuations : instructions, trace, heap, environment, pc

## Auxiliary functions

succ I l =
 | goto l'                                -> [l']
 | branch _ l' l''                        -> [l', l'']
 | when I = {..., l -> _, l' -> _, ...}   -> [l']
 | _                                      -> []

pred I l =
  { l' ∈ I : succ I l' = l }

Lookup (partial) function, returns a v:
  (H,E)[x] :=
    v    if E ∋ (x ↦ const v)
    H(l) if E ∋ (x ↦ mut l)

Update (partial) function, returns an H:
  (H,E)[x ← v] :=
    H[E(x) ↦ v] if E ∋ (x ↦ mut l)

## Evaluation of simple expressions:

  eval H E x = (H,E)[x]
  eval H E lit = lit
  eval H E primop(v, ...) = 〚primop〛(v, ...)

## Osr transformation of environment

  osr-env H E (const x = e) = (x ↦ eval H E e)
  osr-env H E (mut x)       = (x ↦ ⊥)
  osr-env H E (mut x = y)   = (x ↦ a)
    where a = E(y)

## Reduction relation '-->'

  (P, C*) : (I, T, H, E, l) --> (P, C*) : step I(l) (P, I, T, H, E, l)

  (P, C*) : (I, T, H, E, l) --> (P, (C*, C')) : (I', T, H, E', start)
    when I(l) = (const x' = call f (e, ...))
     and Df ∈ dom P
     and Df  = Function f (x, ...)
     and I' := P(Df, Segment active)
     and E' := (x ↦ eval H E e, ...)
     and C' := (x', E, I, succ I l)

  (P, (C*, C')) : (I, T, H, E, l) --> (P, C*) : (I', T, H, E'', l')
    when I(l) = (return e)
     and v   := eval H E e
     and C'   = (x', E', I', l')
     and E'' := E'[x' ↦ v]

## One step reduction

  step   (const x = e) (P, I, T, H, E, l)
       = (I, T, H, E[x ↦ v], succ I l)
    when v := eval H E e

  step   (mut x = e) (P, I, T, H, E, l)
       = (I, T, H[a ↦ v], E[x ↦ a], succ I l)
    when v := eval H E e
     and a - fresh

  step   (x ← e) (P, I, T, H, E, l)
       = (I, T, (H,E)[x ← v], E, succ I l)
    when v := eval H E e

  step   (print e) (P, I, T, H, E, l)
       = (I, (T, v), H, E, succ I l)
    when v := eval H E e

  step   (branch e l₁ l₂) (P, I, T, H, E, l)
       = (I, T, H, E, l')
    when v  := eval H E e
     and l' := if v = true  then l₁
               if v = false then l₂

  step   osr(e, m^, l^, (osr-map, ...)) (P, I, T, H, E, l)
       = (I', T, H, E', l')
    when v := eval H E e
     and if v = false then
         I' := I
         l' := l
         E' := E
     and if v = true then
         I' := P(m^)
         l' := l^
         E' := (osr-env H E osr-map, ...)

# Scopes

declares i =
  | mut x _         -> [x]
  | const x _       -> [x]
  | _               -> []

requires i =
  | mut x = e
  | const x = e
  | osr (e, v, l, (x = ee)*)
                    -> vars(e) ∪ vars(ee)*
  | x <- e          -> x :: vars(e)
  | branch x _
  | print x         -> [x]
  | _               -> []

scope S ::= x*
scope assignment A ::= ((v, l) → S)*

## Declarative scoping judgment

This judgment just classifies "possible" scope assignments A for
a program P. It does not characterize the tightest possible
assignment¹, as it allows to implicitly drop variables from scope on
each transition (the ⊇ relations in the (v, l → i) rule). In
particular, it cannot forbid shadowing, as it is always possible to
drop all same-named bindings before a declaration.

¹: the tightest possible assignment can be defined impredicatively as
the pointwise intersection of all valid judgments, which is
well-defined given that valid scopes are bounded by the set of
variables defined in the program.

  ∀(v → M) ∈ P:   A, P ⊨d v → M
  ----------------------------
            A, P ⊨d

  ∀(l → i) ∈ M:   A, P ⊨d v, l → i
  -------------------------------
         A, P ⊨d v → M

  requires i ⊆ A(v,l)
  ∀l' ∈ succ(P(v),l),  A(v,l) ∪ declares i ⊇ A(v,l')
  A, P ⊨d i : A(v,l)
  pred(P(v), l) = ∅  ⇒  i = start
  -----------------------------------------------------------
  A, P ⊨d v, l → i

The judgment (A, P ⊨d i : S) below is the instruction-specific judgment
that checks the scope restrictions that are specific to each
instruction, rather than the general control-flow constraints and the
generic requires/declares handling.

  -----------------
  A, P ⊨d start : ∅

              A(v', l') = x*
  -------------------------------------
  A, P ⊨d osr(e, v', l', (x = ee*)) : S

  ---------------
  A, P ⊨d stop : ∅

  i ∉ {start, osr, stop}
  ----------------------
  A, P ⊨d i : S

## Algorithmic scoping judgment

(A, P ⊨a), (A, P ⊨a v → M), (A, P ⊨a i : S): as in the declarative
scoping judgment. Only (A, P ⊨a v, l → i) differs.

  S := A(v,l) \ declares i
  (⋂_{l* ∈ pred(P(v),l)} A(v,l*)) = S ∪ requires i
  A, P ⊨a i : S
  ------------------------------------------------
  A, P ⊨a v, l → i

There is a fundamental difference in the role of the scope assignment
A between the declarative and algorithmic judgments.

In the declarative judgment, A(v,l) points to the variables
*available* in the *ingoing* scope of the instruction at location
(v,l): the scope that is available when arriving to the instruction
from a predecessor. The variables that are available in the outgoing
scope can be computed from this value as (A(v,l) ∪ declares i).

In the algorithmic judgment, A(v,l) points to the variables that are
*required* in the *outgoing* scope of the instruction at location
(v,l): the scope that is required when leaving the instruction to
a successor. The variables required in the ingoing scope can be
computed from this value as (A(v,l) \ declares i).

In the declarative judgment, the relation between an instruction scope
and its neighbors is under-specified: a predecessor's outgoing scope
may have more variables than our ingoing scope, and any successor's
ingoing scope may have less variable than our outgoing scope.

In the algorithmic judgment, the relation between the scopes of an
instruction and its neighbors is deterministic: an instruction's
ingoing scope is exactly the variables that are common among all its
predecessors. Implicitly dropping a variable that will never be used
again is possible: this is done by choosing a A(v,l) that is smaller
than the instruction's ingoing set plus (declares i).

Problem: I think there is a problem with the notion of outgoing scope
as it is currently defined for multi-successor instructions, as it
forces all successors to see the same set of required
variables. I think that introducing `drop` instructions would be the
cleanest way to work around these issues – by removing any
underspecification from the declarative specification.
